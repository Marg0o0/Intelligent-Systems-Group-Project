{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aec53e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skfuzzy as fuzz\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d9e4643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 track_id                 artists  \\\n",
      "0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
      "1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
      "2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
      "3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
      "4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
      "\n",
      "                                          album_name  \\\n",
      "0                                             Comedy   \n",
      "1                                   Ghost (Acoustic)   \n",
      "2                                     To Begin Again   \n",
      "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
      "4                                            Hold On   \n",
      "\n",
      "                   track_name  popularity  duration_ms  explicit  \\\n",
      "0                      Comedy          73       230666     False   \n",
      "1            Ghost - Acoustic          55       149610     False   \n",
      "2              To Begin Again          57       210826     False   \n",
      "3  Can't Help Falling In Love          71       201933     False   \n",
      "4                     Hold On          82       198853     False   \n",
      "\n",
      "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
      "0         0.676  0.4610    1    -6.746     0       0.1430        0.0322   \n",
      "1         0.420  0.1660    1   -17.235     1       0.0763        0.9240   \n",
      "2         0.438  0.3590    0    -9.734     1       0.0557        0.2100   \n",
      "3         0.266  0.0596    0   -18.515     1       0.0363        0.9050   \n",
      "4         0.618  0.4430    2    -9.681     1       0.0526        0.4690   \n",
      "\n",
      "   instrumentalness  liveness  valence    tempo  time_signature track_genre  \n",
      "0          0.000001    0.3580    0.715   87.917               4    acoustic  \n",
      "1          0.000006    0.1010    0.267   77.489               4    acoustic  \n",
      "2          0.000000    0.1170    0.120   76.332               4    acoustic  \n",
      "3          0.000071    0.1320    0.143  181.740               3    acoustic  \n",
      "4          0.000000    0.0829    0.167  119.949               4    acoustic  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(114000, 20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acesso ao dataset\n",
    "music = pd.read_csv('dataset.csv', index_col=0) #chama o ficheiro e remove coluna desnecessária (index_col)\n",
    "\n",
    "#Garantir que o acesso foi bem sucedido (faz print das primeiras 5 linhas do dataset)\n",
    "print(music.head())\n",
    "music.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a541e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes da limpeza: 32656 músicas duplicadas\n",
      "track_id            0\n",
      "artists             1\n",
      "album_name          1\n",
      "track_name          1\n",
      "popularity          0\n",
      "duration_ms         0\n",
      "explicit            0\n",
      "danceability        0\n",
      "energy              0\n",
      "key                 0\n",
      "loudness            0\n",
      "mode                0\n",
      "speechiness         0\n",
      "acousticness        0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "valence             0\n",
      "tempo               0\n",
      "time_signature      0\n",
      "track_genre         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##limpeza do dataset\n",
    "# Contar quantas linhas duplicadas existem (mesmo nome + mesmo artista)\n",
    "duplicadas_antes = music.duplicated(subset=[\"track_name\", \"artists\"]).sum()\n",
    "print(f\"Antes da limpeza: {duplicadas_antes} músicas duplicadas\")\n",
    "\n",
    "# Remover duplicados (mesmo nome e mesmo artista)\n",
    "music = music.drop_duplicates(subset=[\"track_name\", \"artists\"], keep=\"first\")\n",
    "\n",
    "#valores em falta por coluna\n",
    "print(music.isnull().sum()) \n",
    "music = music.dropna()  #por serem poucos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1084acc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.461 0.166 0.359 ... 0.329 0.506 0.487]\n",
      "['acoustic' 'acoustic' 'acoustic' ... 'world-music' 'world-music'\n",
      " 'world-music']\n",
      "[0.715 0.267 0.12 ... 0.743 0.413 0.708]\n",
      "[[0.676 0.461 1 ... 87.917 4 'acoustic']\n",
      " [0.42 0.166 1 ... 77.489 4 'acoustic']\n",
      " [0.438 0.359 0 ... 76.332 4 'acoustic']\n",
      " ...\n",
      " [0.629 0.329 0 ... 132.378 4 'world-music']\n",
      " [0.587 0.506 7 ... 135.96 4 'world-music']\n",
      " [0.526 0.487 1 ... 79.198 4 'world-music']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(81343, 20)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defenir as features\n",
    "f0 = music['danceability'].values   #[0,1]\n",
    "f1 = music['energy'].values         #[0,1]\n",
    "f2 = music['key'].values            #[-1,11]\n",
    "f3 = music['loudness'].values       #dB\n",
    "f4 = music['mode'].values           #binary\n",
    "f5 = music['acousticness'].values   #[0,1]\n",
    "f6 = music['tempo'].values          #bpm\n",
    "f7 = music['time_signature'].values #[0,5]\n",
    "f8 = music['track_genre'].values    #classes\n",
    "\n",
    "y = music.values[:, 16]    #valence-target\n",
    "#COVERTER NOMES EM NUMEROOSSSS\n",
    "'------------------------------------'\n",
    "\n",
    "\n",
    "\n",
    "# matriz features\n",
    "x = music.values[:, [7, 8, 9, 10, 11, 13, 17, 18, 19]]\n",
    "#x = music[['danceability', 'energy', 'key',.....]]    \n",
    "'-------------------------------------melhor metodo?'\n",
    "\n",
    "print(f1)\n",
    "print(f8)\n",
    "print(y)\n",
    "print(x)\n",
    "music.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c21e9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depois da limpeza: 0 músicas duplicadas\n"
     ]
    }
   ],
   "source": [
    "#verificaçaõ da limpeza\n",
    "duplicadas_depois = music.duplicated(subset=[\"track_name\", \"artists\"]).sum()\n",
    "print(f\"Depois da limpeza: {duplicadas_depois} músicas duplicadas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18f9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-------------------------------------------------'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train, validation e test split\n",
    "test_size = 0.3\n",
    "val_size = 0.5   #será metade dos dados de teste\n",
    "#Seprarar o conjunto de treino (70%) e o temporário (30%)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size = test_size, random_state = 42)\n",
    "#Separar o conjunto temporário em teste (15%) e validação (15%)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x, y, test_size = val_size, RandomState = 42)\n",
    "\n",
    "'test será o conjunto nunca visto pelo algoritmo até ao fim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce6aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.728 0.234 7 ... 154.013 4 'chill']\n",
      " [0.724 0.759 9 ... 101.943 4 'edm']\n",
      " [0.523 0.26 2 ... 110.512 4 'romance']\n",
      " ...\n",
      " [0.487 0.398 5 ... 109.389 3 'tango']\n",
      " [0.564 0.731 9 ... 95.036 4 'acoustic']\n",
      " [0.676 0.951 9 ... 85.72 4 'comedy']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'----------PORQUE NÃO POSSO FAZER A NORMALIZAÇÃO ANTES DE SEPARAR ENTRE TESTE E TREINO\\nOU SEJA DÁ PARA O FAZER SEM LEVAR A OVER FITTING?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalizar varivaeis Key, loudness, tempo, time_signature\n",
    "#scaler = StandardScaler()\n",
    "#x_train[ :, [ 2, 3, 6, 7]] = scaler.fit_transform(x_train[ :, [ 2, 3, 6, 7]])\n",
    "#x_val[ :, [ 2, 3, 6, 7]] = scaler.transform(x_val[ :, 2, 3, 6, 7])\n",
    "\n",
    "print(x_train)\n",
    "\n",
    "'''----------PORQUE NÃO POSSO FAZER A NORMALIZAÇÃO ANTES DE SEPARAR ENTRE TESTE E TREINO\n",
    "OU SEJA DÁ PARA O FAZER SEM LEVAR A OVER FITTING?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c8f91ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.728 0.234 0.6363636363636364 ... 0.6918667595067497 0.8 'chill']\n",
      " [0.724 0.759 0.8181818181818182 ... 0.45795467307562726 0.8 'edm']\n",
      " [0.523 0.26 0.18181818181818182 ... 0.4964488668268907 0.8 'romance']\n",
      " ...\n",
      " [0.487 0.398 0.4545454545454546 ... 0.49140405651265695\n",
      "  0.6000000000000001 'tango']\n",
      " [0.564 0.731 0.8181818181818182 ... 0.4269266188989466 0.8 'acoustic']\n",
      " [0.676 0.951 0.8181818181818182 ... 0.3850767053749916 0.8 'comedy']]\n"
     ]
    }
   ],
   "source": [
    "#Normalizar varivaeis Key, loudness, tempo, time_signature\n",
    "scaler = MinMaxScaler()\n",
    "x_train[ :, [ 2, 3, 6, 7]] = scaler.fit_transform(x_train[ :, [ 2, 3, 6, 7]])\n",
    "#x_val[ :, [ 2, 3, 6, 7]] = scaler.transform(x_val[ :, 2, 3, 6, 7])\n",
    "\n",
    "print(x_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
