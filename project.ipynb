{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA \n",
    "import skfuzzy as fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm   \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name', 'popularity', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#download dataset\n",
    "path = kagglehub.dataset_download(\"maharshipandya/-spotify-tracks-dataset\")\n",
    "\n",
    "#load CSV into a pandas dataframe\n",
    "dataset = pd.read_csv(f\"{path}/dataset.csv\")\n",
    "\n",
    "#see the first rows\n",
    "#print(dataset.head())\n",
    "#print(dataset.shape)\n",
    "\n",
    "# see the features available\n",
    "print(list(dataset.columns)) \n",
    "#print(dataset.iloc[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove duplicates, speech-like tracks and rows with missing entries\n",
    "dataset = dataset.drop_duplicates(subset=[\"track_name\", \"artists\"], keep=\"first\")\n",
    "dataset = dataset[dataset['speechiness'] <= 0.66]\n",
    "dataset = dataset.dropna() \n",
    "\n",
    "#number of unique genres after pre-processing\n",
    "#num_genres = dataset['track_genre'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#select relevant features\n",
    "selected_features = [\n",
    "    'danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "    'acousticness', 'instrumentalness', 'valence', 'tempo'\n",
    "]\n",
    "\n",
    "#subset the dataset\n",
    "X = dataset[selected_features].values\n",
    "y = dataset['track_genre'].values\n",
    "\n",
    "#create labels for the genres\n",
    "le = LabelEncoder()\n",
    "y_id = le.fit_transform(y)\n",
    "num_genres = len(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 56337\n",
      "Validation: 12072\n",
      "Test: 12073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#split proportions\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "\n",
    "#split into train (.7) and temp (.3)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y_id, test_size=(test_size + val_size), random_state=42,\n",
    ")\n",
    "\n",
    "#split temp into validation (.15) and test (.15)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=(test_size / (test_size + val_size)), random_state=42,\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(X_train))\n",
    "print(\"Validation:\", len(X_val))\n",
    "print(\"Test:\", len(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler=StandardScaler()\n",
    "X_train[:, [2, 3, 8]] = scaler.fit_transform(X_train[:, [2, 3, 8]])\n",
    "X_val[:, [2, 3, 8]]   = scaler.transform(X_val[:, [2, 3, 8]])\n",
    "X_test[:, [2, 3, 8]]  = scaler.transform(X_test[:, [2, 3, 8]])\n",
    "\n",
    "#print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hyperparameters\n",
    "embedding_dim = 10     #inicialmente 30, reduzimos para 10\n",
    "num_epochs = 10        #a partir de 7 epochs, loss < 1%\n",
    "learning_rate = 0.001  #se calhar diminuir para nao perder informação na rede\n",
    "dropout = 0.2\n",
    "batch_size = 64\n",
    "\n",
    "#data conversion to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.long)\n",
    "X_val = torch.tensor(X_val, dtype = torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype = torch.long)\n",
    "\n",
    "#create dataset and loader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#genre encoder (y -> z)\n",
    "class GenreEncoder(nn.Module):\n",
    "    def __init__(self, num_genres, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_genres, embedding_dim)\n",
    "\n",
    "    def forward(self, genre_id):\n",
    "        if genre_id.dim() == 2 and genre_id.size(1) == 1:\n",
    "            genre_id = genre_id.squeeze(1)\n",
    "        z = self.embedding(genre_id)  # [batch, embedding_dim]\n",
    "        return z\n",
    "\n",
    "#feature encoder (x -> ẑ)\n",
    "class FeatureEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, dropout_prob = 0.3):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear (input_dim, 64)\n",
    "        self.hidden1 = nn.Linear (64, 64)\n",
    "        self.hidden2 = nn.Linear (64, 64)\n",
    "        self.out = nn.Linear (64, embedding_dim)\n",
    "        self.dropout = nn.Dropout (p = dropout_prob)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu (self.input(x)); x = self.dropout(x)\n",
    "\n",
    "        x = F.relu (self.hidden1(x)); x = self.dropout(x)\n",
    "\n",
    "        x = F.relu (self.hidden2(x)); x = self.dropout(x)\n",
    "\n",
    "        z_hat = self.out(x)\n",
    "        return z_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCosineSimilarity(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#optimizer\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenre_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\optim\\adam.py:101\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor betas[1] must be 1-element\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m     89\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m     90\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m     decoupled_weight_decay\u001b[38;5;241m=\u001b[39mdecoupled_weight_decay,\n\u001b[0;32m    100\u001b[0m )\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\optim\\optimizer.py:400\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    397\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_compile.py:46\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m disable_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dynamo_disable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# We can safely turn off functools.wraps here because the inner\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# already wraps fn in the outer scope.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive, wrapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_dynamo\\__init__.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_dynamo\\convert_frame.py:53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_dynamo\\symbolic_convert.py:58\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_method\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     59\u001b[0m     config,\n\u001b[0;32m     60\u001b[0m     exc,\n\u001b[0;32m     61\u001b[0m     graph_break_hints,\n\u001b[0;32m     62\u001b[0m     logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging,\n\u001b[0;32m     63\u001b[0m     trace_rules,\n\u001b[0;32m     64\u001b[0m     variables,\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     67\u001b[0m     get_indexof,\n\u001b[0;32m     68\u001b[0m     JUMP_OPNAMES,\n\u001b[0;32m     69\u001b[0m     livevars_analysis,\n\u001b[0;32m     70\u001b[0m     propagate_line_nums,\n\u001b[0;32m     71\u001b[0m )\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     73\u001b[0m     cleaned_instructions,\n\u001b[0;32m     74\u001b[0m     create_call_function,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m     unique_id,\n\u001b[0;32m     82\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_dynamo\\trace_rules.py:47\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, cast, Optional, Union\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_operators\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_content_store\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_inductor\\__init__.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, IO, Literal, Optional, TYPE_CHECKING, Union\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstandalone_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompiledArtifact  \u001b[38;5;66;03m# noqa: TC001\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_inductor\\config.py:533\u001b[0m\n\u001b[0;32m    528\u001b[0m autoheuristic_log_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHINDUCTOR_AUTOHEURISTIC_LOG_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEFAULT\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    530\u001b[0m )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Disabled by default on ROCm, opt-in if model utilises NHWC convolutions\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m layout_opt_default \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241m.\u001b[39mhip \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m layout_optimization \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    535\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHINDUCTOR_LAYOUT_OPTIMIZATION\u001b[39m\u001b[38;5;124m\"\u001b[39m, layout_opt_default) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m )\n\u001b[0;32m    538\u001b[0m force_layout_optimization \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHINDUCTOR_FORCE_LAYOUT_OPT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\__init__.py:2745\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   2742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _lazy_modules:\n\u001b[0;32m   2743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m-> 2745\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "\n",
    "genre_embedding = GenreEncoder(num_genres, embedding_dim)\n",
    "\n",
    "model = FeatureEncoder(\n",
    "    input_dim = X_train.shape[1], \n",
    "    embedding_dim = embedding_dim, dropout_prob = dropout\n",
    ")\n",
    "\n",
    "#loss\n",
    "criterion = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "#optimizer\n",
    "optimizer = optim.Adam(\n",
    "    list(model.parameters()) + list(genre_embedding.parameters()),\n",
    "    lr = learning_rate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    genre_embedding.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for x_feat, y_genre in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        z = genre_embedding(y_genre)\n",
    "        \n",
    "        z_hat = model(x_feat)\n",
    "\n",
    "        cos_sim = criterion( z_hat, z)\n",
    "        loss = 1 - cos_sim.mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#aqui está para visualizar os K generos mais frequentes\n",
    "\n",
    "model.eval(); genre_embedding.eval()\n",
    "with torch.no_grad():\n",
    "    Zhat_val = model(X_val).cpu().numpy()      # [N_val, emb]\n",
    "    y_val_np = y_val.cpu().numpy()\n",
    "\n",
    "#top-K genres\n",
    "K = 10\n",
    "counts_all = pd.Series(y_id).value_counts()\n",
    "topK_ids = counts_all.index[:K].to_numpy()\n",
    "topK_names = le.inverse_transform(topK_ids)\n",
    "\n",
    "# filter validation to those K\n",
    "mask = np.isin(y_val_np, topK_ids)\n",
    "Z = Zhat_val[mask]\n",
    "y_small = y_val_np[mask]\n",
    "\n",
    "# subsample for speed if needed\n",
    "rng = np.random.RandomState(42)\n",
    "max_points = 4000\n",
    "if len(Z) > max_points:\n",
    "    id = rng.choice(len(Z), size=max_points, replace=False)\n",
    "    Z = Z[id]; y_small = y_small[id]\n",
    "\n",
    "# normalize (cosine), PCA -> t-SNE\n",
    "Zn = Z / (np.linalg.norm(Z, axis=1, keepdims=True) + 1e-12)\n",
    "pca = PCA(n_components=min(50, Z.shape[1]), random_state=42)\n",
    "Zp = pca.fit_transform(Zn)\n",
    "\n",
    "perp = min(50, max(5, len(Zp)//200))\n",
    "tsne = TSNE(n_components=2, perplexity=perp, learning_rate='auto',\n",
    "            init='pca', metric='cosine', random_state=42)\n",
    "Z2 = tsne.fit_transform(Zp)\n",
    "\n",
    "#plot\n",
    "\n",
    "cmap = cm.get_cmap('tab20', K)\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "for i, gid in enumerate(topK_ids):\n",
    "    m = (y_small == gid)\n",
    "    plt.scatter(Z2[m,0], Z2[m,1], s=10, color=cmap(i), alpha=0.8, label=topK_names[i])\n",
    "plt.legend(title=\"Genres (global Top-K)\", bbox_to_anchor=(1.02,1), loc=\"upper left\", fontsize=8)\n",
    "plt.title(f\"t-SNE of $\\\\hat{{z}}$ (global top {K} genres, metric=cosine, perp={perp})\")\n",
    "plt.xlabel(\"t-SNE 1\"); plt.ylabel(\"t-SNE 2\")\n",
    "plt.tight_layout(); plt.show()\n",
    "print(\"plot ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuzzy c-means clustering - sem visualização\n",
    "\n",
    "# ---- Extract genre embeddings after training ----\n",
    "genre_embedding.eval()\n",
    "Zgenres = genre_embedding.embedding.weight.detach().cpu().numpy()   # [num_genres, embedding_dim]\n",
    "\n",
    "# ---- Normalize (cosine geometry) ----\n",
    "Zg = Zgenres / (np.linalg.norm(Zgenres, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "# ---- Fuzzy C-Means clustering ----\n",
    "c = 8       # number of broad clusters\n",
    "m = 2.0      # fuzziness parameter\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    Zg.T, c=c, m=m, error=1e-6, maxiter=1000, init=None, seed=42\n",
    ")\n",
    "print(f\"Fuzzy partition coefficient (FPC): {fpc:.3f}\")\n",
    "\n",
    "# ---- Hard cluster assignment + confidence ----\n",
    "labels_hard = u.argmax(axis=0)    # cluster index for each genre\n",
    "labels_conf = u.max(axis=0)       # highest membership value (confidence)\n",
    "\n",
    "# ---- Build table: micro-genre -> cluster info ----\n",
    "genre_names_all = le.classes_\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"genre\": genre_names_all,\n",
    "    \"cluster\": labels_hard,\n",
    "    \"membership\": labels_conf\n",
    "}).sort_values([\"cluster\", \"membership\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTop rows of fuzzy cluster mapping:\")\n",
    "print(df_clusters.head(50))\n",
    "\n",
    "# ---- Map every song's genre ID to its cluster ID ----\n",
    "cluster_of_genre = labels_hard\n",
    "y_train_cluster = cluster_of_genre[y_train.cpu().numpy()]\n",
    "y_val_cluster   = cluster_of_genre[y_val.cpu().numpy()]\n",
    "y_test_cluster  = cluster_of_genre[y_test]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
