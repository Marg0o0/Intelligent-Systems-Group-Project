{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA \n",
    "import skfuzzy as fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm   \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#download dataset\n",
    "path = kagglehub.dataset_download(\"maharshipandya/-spotify-tracks-dataset\")\n",
    "\n",
    "#load CSV into a pandas dataframe\n",
    "dataset = pd.read_csv(f\"{path}/dataset.csv\")\n",
    "\n",
    "#see the first rows\n",
    "#print(dataset.head())\n",
    "#print(dataset.shape)\n",
    "\n",
    "# see the features available\n",
    "print(list(dataset.columns)) \n",
    "#print(dataset.iloc[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove duplicates, speech-like tracks and rows with missing entries\n",
    "dataset = dataset.drop_duplicates(subset=[\"track_name\", \"artists\"], keep=\"first\")\n",
    "dataset = dataset[dataset['speechiness'] <= 0.66]\n",
    "dataset = dataset.dropna() \n",
    "\n",
    "#number of unique genres after pre-processing\n",
    "#num_genres = dataset['track_genre'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#select relevant features\n",
    "selected_features = [\n",
    "    'danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "    'acousticness', 'instrumentalness', 'valence', 'tempo'\n",
    "]\n",
    "\n",
    "#subset the dataset\n",
    "X = dataset[selected_features].values\n",
    "y = dataset['track_genre'].values\n",
    "\n",
    "#create labels for the genres\n",
    "le = LabelEncoder()\n",
    "y_id = le.fit_transform(y)\n",
    "num_genres = len(le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#split proportions\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "\n",
    "#split into train (.7) and temp (.3)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y_id, test_size=(test_size + val_size), random_state=42,\n",
    ")\n",
    "\n",
    "#split temp into validation (.15) and test (.15)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=(test_size / (test_size + val_size)), random_state=42,\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(X_train))\n",
    "print(\"Validation:\", len(X_val))\n",
    "print(\"Test:\", len(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler=StandardScaler()\n",
    "X_train[:, [2, 3, 8]] = scaler.fit_transform(X_train[:, [2, 3, 8]])\n",
    "X_val[:, [2, 3, 8]]   = scaler.transform(X_val[:, [2, 3, 8]])\n",
    "X_test[:, [2, 3, 8]]  = scaler.transform(X_test[:, [2, 3, 8]])\n",
    "\n",
    "#print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hyperparameters\n",
    "embedding_dim = 10     #inicialmente 30, reduzimos para 10\n",
    "num_epochs = 10        #a partir de 7 epochs, loss < 1%\n",
    "learning_rate = 0.001  #se calhar diminuir para nao perder informação na rede\n",
    "dropout = 0.2\n",
    "batch_size = 64\n",
    "\n",
    "#data conversion to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.long)\n",
    "X_val = torch.tensor(X_val, dtype = torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype = torch.long)\n",
    "\n",
    "#create dataset and loader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#genre encoder (y -> z)\n",
    "class GenreEncoder(nn.Module):\n",
    "    def __init__(self, num_genres, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_genres, embedding_dim)\n",
    "\n",
    "    def forward(self, genre_id):\n",
    "        if genre_id.dim() == 2 and genre_id.size(1) == 1:\n",
    "            genre_id = genre_id.squeeze(1)\n",
    "        z = self.embedding(genre_id)  # [batch, embedding_dim]\n",
    "        return z\n",
    "\n",
    "#feature encoder (x -> ẑ)\n",
    "class FeatureEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, dropout_prob = 0.3):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear (input_dim, 64)\n",
    "        self.hidden1 = nn.Linear (64, 64)\n",
    "        self.hidden2 = nn.Linear (64, 64)\n",
    "        self.out = nn.Linear (64, embedding_dim)\n",
    "        self.dropout = nn.Dropout (p = dropout_prob)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu (self.input(x)); x = self.dropout(x)\n",
    "\n",
    "        x = F.relu (self.hidden1(x)); x = self.dropout(x)\n",
    "\n",
    "        x = F.relu (self.hidden2(x)); x = self.dropout(x)\n",
    "\n",
    "        z_hat = self.out(x)\n",
    "        return z_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genre_embedding = GenreEncoder(num_genres, embedding_dim)\n",
    "\n",
    "model = FeatureEncoder(\n",
    "    input_dim = X_train.shape[1], \n",
    "    embedding_dim = embedding_dim, dropout_prob = dropout\n",
    ")\n",
    "\n",
    "#loss\n",
    "criterion = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "#optimizer\n",
    "optimizer = optim.Adam(\n",
    "    list(model.parameters()) + list(genre_embedding.parameters()),\n",
    "    lr = learning_rate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    genre_embedding.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for x_feat, y_genre in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        z = genre_embedding(y_genre)\n",
    "        \n",
    "        z_hat = model(x_feat)\n",
    "\n",
    "        cos_sim = criterion( z_hat, z)\n",
    "        loss = 1 - cos_sim.mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#visualizar os K generos mais frequentes\n",
    "\n",
    "model.eval(); genre_embedding.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    Zhat_val = model(X_val).cpu().numpy()\n",
    "    y_val_np = y_val.cpu().numpy()\n",
    "\n",
    "#top-K genres\n",
    "K = 10\n",
    "counts_all = pd.Series(y_id).value_counts()\n",
    "topK_ids = counts_all.index[:K].to_numpy()\n",
    "topK_names = le.inverse_transform(topK_ids)\n",
    "\n",
    "# filter validation to those K\n",
    "mask = np.isin(y_val_np, topK_ids)\n",
    "Z = Zhat_val[mask]\n",
    "y_small = y_val_np[mask]\n",
    "\n",
    "# subsample for speed if needed\n",
    "rng = np.random.RandomState(42)\n",
    "max_points = 4000\n",
    "if len(Z) > max_points:\n",
    "    id = rng.choice(len(Z), size=max_points, replace=False)\n",
    "    Z = Z[id]; y_small = y_small[id]\n",
    "\n",
    "# normalize (cosine), PCA -> t-SNE\n",
    "Zn = Z / (np.linalg.norm(Z, axis=1, keepdims=True) + 1e-12)\n",
    "pca = PCA(n_components=min(50, Z.shape[1]), random_state=42)\n",
    "Zp = pca.fit_transform(Zn)\n",
    "\n",
    "perp = min(50, max(5, len(Zp)//200))\n",
    "tsne = TSNE(n_components=2, perplexity=perp, learning_rate='auto',\n",
    "            init='pca', metric='cosine', random_state=42)\n",
    "Z2 = tsne.fit_transform(Zp)\n",
    "\n",
    "#plot\n",
    "\n",
    "cmap = cm.get_cmap('tab20', K)\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "for i, gid in enumerate(topK_ids):\n",
    "    m = (y_small == gid)\n",
    "    plt.scatter(Z2[m,0], Z2[m,1], s=10, color=cmap(i), alpha=0.8, label=topK_names[i])\n",
    "plt.legend(title=\"Genres (global Top-K)\", bbox_to_anchor=(1.02,1), loc=\"upper left\", fontsize=8)\n",
    "plt.title(f\"t-SNE of $\\\\hat{{z}}$ (global top {K} genres, metric=cosine, perp={perp})\")\n",
    "plt.xlabel(\"t-SNE 1\"); plt.ylabel(\"t-SNE 2\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 interpretable genres for visualization WITH PCA!!!!\n",
    "\n",
    "selected_genres = [\n",
    "    'pop', 'indie-pop', 'rock', 'metal', 'hip-hop',\n",
    "    'jazz', 'electronic', 'classical', 'country', 'reggae'\n",
    "]\n",
    "\n",
    "# Find their encoded IDs (skip ones not in the dataset)\n",
    "existing = [g for g in selected_genres if g in le.classes_]\n",
    "selected_ids = le.transform(existing)\n",
    "\n",
    "print(\"Genres selected for visualization:\")\n",
    "print(existing)\n",
    "\n",
    "# Mask the validation set to include only these genres\n",
    "mask = np.isin(y_val.cpu().numpy(), selected_ids)\n",
    "Z = model(X_val[mask]).detach().cpu().numpy()\n",
    "y_small = y_val.cpu().numpy()[mask]\n",
    "\n",
    "# L2-normalize embeddings (for cosine geometry)\n",
    "Z_norm = Z / (np.linalg.norm(Z, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "# PCA → 2D projection\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "Z2 = pca.fit_transform(Z_norm)\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "cmap = cm.get_cmap('tab10', len(existing))\n",
    "\n",
    "for i, gid in enumerate(selected_ids):\n",
    "    m = (y_small == gid)\n",
    "    plt.scatter(Z2[m,0], Z2[m,1], s=10, color=cmap(i), alpha=0.8, label=existing[i])\n",
    "\n",
    "plt.title(\"Visualization of selected popular genres (2D PCA of $\\hat{z}$)\")\n",
    "plt.xlabel(\"PCA 1\"); plt.ylabel(\"PCA 2\")\n",
    "plt.legend(bbox_to_anchor=(1.02,1), loc='upper left', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the embeddings (Zhat_val) and corresponding labels (y_val_np)\n",
    "with torch.no_grad():\n",
    "    Zhat_val = model(X_val).cpu().numpy()\n",
    "    y_val_np = y_val.cpu().numpy()\n",
    "\n",
    "# Define the genres you want to visualize\n",
    "selected_genres = [\n",
    "    'pop', 'indie-pop', 'rock', 'metal', 'hip-hop',\n",
    "    'jazz', 'electronic', 'classical', 'country', 'reggae'\n",
    "]\n",
    "\n",
    "# Keep only genres that exist in the dataset and get their encoded IDs\n",
    "existing = [g for g in selected_genres if g in le.classes_]\n",
    "selected_ids = le.transform(existing)\n",
    "\n",
    "print(\"Genres selected for visualization:\")\n",
    "print(existing)\n",
    "\n",
    "# Filter the validation data to include only the selected genres\n",
    "mask = np.isin(y_val_np, selected_ids)\n",
    "Z = Zhat_val[mask]\n",
    "y_small = y_val_np[mask]\n",
    "\n",
    "# Optionally subsample points for faster visualization (keeps up to 4000)\n",
    "rng = np.random.RandomState(42)\n",
    "max_points = 4000\n",
    "if len(Z) > max_points:\n",
    "    idx = rng.choice(len(Z), size=max_points, replace=False)\n",
    "    Z = Z[idx]\n",
    "    y_small = y_small[idx]\n",
    "\n",
    "# Normalize embeddings (unit vectors) to use cosine distance correctly\n",
    "Zn = Z / (np.linalg.norm(Z, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "# Apply PCA for dimensionality reduction before t-SNE (helps speed and stability)\n",
    "pca = PCA(n_components=min(50, Z.shape[1]), random_state=42)\n",
    "Zp = pca.fit_transform(Zn)\n",
    "\n",
    "# Define t-SNE perplexity dynamically based on data size\n",
    "perp = min(50, max(5, len(Zp)//200))\n",
    "\n",
    "# Run t-SNE to project embeddings into 2D space for visualization\n",
    "tsne = TSNE(\n",
    "    n_components=2, perplexity=perp, learning_rate='auto',\n",
    "    init='pca', metric='cosine', random_state=42\n",
    ")\n",
    "Z2 = tsne.fit_transform(Zp)\n",
    "\n",
    "# Plot the 2D t-SNE map with colors for each selected genre\n",
    "cmap = cm.get_cmap('tab10', len(existing))\n",
    "plt.figure(figsize=(9,7))\n",
    "for i, gid in enumerate(selected_ids):\n",
    "    m = (y_small == gid)\n",
    "    plt.scatter(Z2[m,0], Z2[m,1], s=10, color=cmap(i), alpha=0.8, label=existing[i])\n",
    "\n",
    "plt.legend(title=\"Selected Genres\", bbox_to_anchor=(1.02,1), loc=\"upper left\", fontsize=8)\n",
    "plt.title(f\"t-SNE of $\\\\hat{{z}}$ (selected genres, metric=cosine, perp={perp})\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuzzy c-means clustering - sem visualização\n",
    "\n",
    "# ---- Extract genre embeddings after training ----\n",
    "genre_embedding.eval()\n",
    "Zgenres = genre_embedding.embedding.weight.detach().cpu().numpy()   # [num_genres, embedding_dim]\n",
    "\n",
    "# ---- Normalize (cosine geometry) ----\n",
    "Zg = Zgenres / (np.linalg.norm(Zgenres, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "# ---- Fuzzy C-Means clustering ----\n",
    "c = 8       # number of broad clusters\n",
    "m = 2.0      # fuzziness parameter\n",
    "cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    Zg.T, c=c, m=m, error=1e-6, maxiter=1000, init=None, seed=42\n",
    ")\n",
    "print(f\"Fuzzy partition coefficient (FPC): {fpc:.3f}\")\n",
    "\n",
    "# ---- Hard cluster assignment + confidence ----\n",
    "labels_hard = u.argmax(axis=0)    # cluster index for each genre\n",
    "labels_conf = u.max(axis=0)       # highest membership value (confidence)\n",
    "\n",
    "# ---- Build table: micro-genre -> cluster info ----\n",
    "genre_names_all = le.classes_\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"genre\": genre_names_all,\n",
    "    \"cluster\": labels_hard,\n",
    "    \"membership\": labels_conf\n",
    "}).sort_values([\"cluster\", \"membership\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTop rows of fuzzy cluster mapping:\")\n",
    "print(df_clusters.head(110))\n",
    "\n",
    "# ---- Map every song's genre ID to its cluster ID ----\n",
    "cluster_of_genre = labels_hard\n",
    "y_train_cluster = cluster_of_genre[y_train.cpu().numpy()]\n",
    "y_val_cluster   = cluster_of_genre[y_val.cpu().numpy()]\n",
    "y_test_cluster  = cluster_of_genre[y_test]\n",
    "\n",
    "print(df_clusters['cluster'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Visualization of fuzzy clusters\n",
    "\n",
    "# Project the genre embeddings (Zg) to 2D with PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "Z2 = pca.fit_transform(Zg)          # shape [num_genres, 2]\n",
    "C2 = pca.transform(cntr)            # cluster centers [c, 2]\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "cmap = plt.cm.get_cmap('tab20', c)\n",
    "\n",
    "# Plot each genre embedding colored by its hard cluster\n",
    "for k in range(c):\n",
    "    m = (labels_hard == k)\n",
    "    plt.scatter(Z2[m,0], Z2[m,1], s=20, color=cmap(k), alpha=0.7, label=f\"C{k}\")\n",
    "\n",
    "# Plot cluster centroids\n",
    "plt.scatter(C2[:,0], C2[:,1], s=250, marker='*', edgecolor='k', facecolor='none', linewidths=1.2, label='centroids')\n",
    "\n",
    "plt.title(f\"Fuzzy C-Means clustering of genre embeddings (c={c}, FPC={fpc:.2f})\")\n",
    "plt.xlabel(\"PCA 1\"); plt.ylabel(\"PCA 2\")\n",
    "plt.legend(bbox_to_anchor=(1.02,1), loc=\"upper left\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
